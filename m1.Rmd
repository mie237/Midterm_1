---
title: "MIE237 Term Test 1"
date: "2016-02-09"
output: pdf_document
---
\newcounter{qnum}
\setcounter{qnum}{0}
\newcommand{\question}{\refstepcounter{qnum}\arabic{qnum}.}



```{r, echo=FALSE, message=FALSE}
library(dplyr)
library(rio)
library(ggplot2)
library(knitr)
source("print_obscure.R")
```

\begin{center}
\textbf{Examination Type B; Calculator Type 2 Permitted}

\textbf{50 Minutes; 40 Marks Available}

\begin{minipage}{12cm}\vspace{1cm}
  Family Name:\hrulefill\\[1cm]
  Given Name:\hrulefill\\[1cm]
  Student Number:\hrulefill\\[1cm]
\end{minipage}
\end{center}

```{r, echo=FALSE}
n <- 102

brands <- c("Camtran", "Nema", "Moloney")
sizes <- c("100KVA", "75KVA", "50KVA")
combos <- expand.grid(brands, sizes)

set.seed(2)
probs <- sample(3:7, 9, TRUE)/9*102
b_s <- combos[sample(1:9, n, prob=probs, replace = TRUE),]
age <- numeric(n)
age[b_s$Var2 == "100KVA"] <- rweibull(sum(b_s$Var2 == "100KVA"),
                                      1.4, 25)
age[b_s$Var2 == "75KVA"] <- rweibull(sum(b_s$Var2 == "75KVA"),
                                      1.6, 30)
age[b_s$Var2 == "50KVA"] <- rweibull(sum(b_s$Var2 == "75KVA"),
                                      1.8, 35)

ID <- replicate(n, paste(c(sample(LETTERS, 2), 
                           sample(0:9, 4, repl=TRUE)), collapse=""))


tx <- data_frame(ID = ID, Manufacturer = b_s$Var1, Size = b_s$Var2,
                 Age = age)

```

**This test contains 10 pages. Pages 6--9 are tables. Page 10 is a formula sheet. You can detach the formula sheet if you like, but please don't detach the tables. (Detaching too many pages causes the test to fall apart.) You may use the backs of pages for rough work.**

An electricity distribution company (a company that delivers electricity to homes and businesses) has accumulated a dataset related to `r n` failed small transformers and wants to analyse some aspects of the data. Here are the first `r (rows <- 10)` rows of the dataset:

```{r, echo=FALSE}
kable(head(tx, rows), digits = 1)
```

The dataset has `r ncol(tx)` variables: ``r paste(colnames(tx), collapse=", ")``. The  variable ``r colnames(tx)[1]`` contains the serial number of the transformer. The variable ``r colnames(tx)[2]`` contains the manufacturer name, one of: ``r paste(brands, collapse=", ")``. The variable ``r colnames(tx)[3]`` contains a description of the transformer's power rating. The variable ``r colnames(tx)[4]`` contains the age in years of the transformer at the time of its failure. 

\pagebreak 

\question{} **(15 marks total)** Here is a table of summary statistics with the count, mean age, and standard deviation of age broken down by manufacturer, followed by a normal quantile plot of the ages for each manufacturer.

```{r, echo=FALSE, fig.height=2.5, fig.align="center"}
tx %>% 
  group_by(Manufacturer) %>% 
  summarise(Count=n(), "Mean Age"=mean(Age), "SD Age"=sd(Age)) %>% 
  kable(digits=2)

tx %>% 
  ggplot(aes(sample=Age)) + stat_qq() + facet_grid(. ~ Manufacturer, scales="free") + theme_bw()
```

Produce a 95% confidence interval for the difference in mean age at failure between ``r brands[1]`` and ``r brands[3]`` transformers, commenting on any relevant assumptions you might have needed to make.

\pagebreak

\question{} **(10 marks total)** The company wants to look at the `Manufacturer` and `Size` variables. Here is a summary table with counts by these two variables, followed by `R` output for the $\chi^2$ test of independence with some values removed (replaced with `MISSING`).

```{r, echo=FALSE, results='asis', message=FALSE}
library(xtable)
size_man <- with(tx, addmargins(table(Manufacturer, Size)))
size_man_xt <- xtable(size_man, align="r|rrr|r", digits = 0)
print.xtable(size_man_xt, hline.after = c(-1,0,3), comment=FALSE)
```

```{r, echo=FALSE}
chi2 <- chisq.test(tx$Size, tx$Manufacturer)
chi2$parameter <- c(df = "MISSING")
chi2$p.value <- "MISSING"
print_obscure(chi2)
```

a. **(3 marks)** Produce a 95% confidence interval for the proportion of transformers that are manufactured by Nema, commenting on any relevant assumptions you might have needed to make.

\vspace{1.25in}

b. **(2 marks)** Compute the "expected cell count" for the top left cell (corresponding to `Camtran` and `100KVA`).

\vspace{0.5in}

c. **(2 marks)** How many out of the 9 expected cell counts would you need to calculate using multiplication and division of marginal totals before you can simply use addition and subtraction to produce the rest?

\vspace{0.5in}

d. **(3 marks)** Perform the test of independence with null hypothesis (informally) expressed as: $H_0:$ `Manufacturer` and `Size` are independent, commenting on any relevant assumptions you might have needed to make.

\pagebreak

\question{} **(10 marks total)** The company happens to still have all the `Moloney` transformers in storage and decides to do some electrical testing on two of the "windings" (essentially, a wire wound around a metal core---the details don't matter) in each of these transformers. Let's call the windings `A` and `B` within each unit. A current is passed through each winding and the amount of heat generated is measured. (If you are a transformer expert and this makes no sense, this is all made up, and please forgive me.)

A summer student working at the company produces the following summaries of the data gathered, consisting of: mean and standard deviation for each of the `A` and `B` winding experiments, and the standard deviation of the unit-by-unit differences between `A` and `B` experiments. 

```{r, echo=FALSE}
tx %>% 
  filter(Manufacturer == "Moloney") %>% summarize(n()) %>% unlist -> n_moloney
tx %>% 
  filter(Manufacturer == "Moloney") %>% 
  mutate(A = 150 + rchisq(n_moloney, 2), B = A + rnorm(n_moloney, 1, 3), 
         "A-B" = A - B) -> tx_AB

tx_AB %>% 
  summarize("Count" = n(),
            "A Temp Mean" = mean(A),
            "A Temp SD" = sd(A),
            "B Temp Mean" = mean(B),
            "B Temp SD" = sd(A),
            "A--B Diff Temp SD" = sd(`A-B`)
            ) %>% kable(digits=2)
```

Here are the normal quantile plots for the `A` and `B` winding experiments and also for the `A-B` differences.

```{r, echo=FALSE, fig.height=2.5, message=FALSE}
library(tidyr)
tx_AB %>% 
  gather(Exp, Value, A:`A-B`) %>% 
  ggplot(aes(sample=Value)) + 
  stat_qq() + 
  facet_wrap( ~ Exp, scales="free_y") + theme_bw()
```

Perform the appropriate hypothesis test to evaluate if there is a difference in temperature between `A` and `B` winding experiments.

\pagebreak

\question{} **(5 marks total)** Consider the simple linear regression model $y_i = \beta_0 + \beta_1 x_i + \varepsilon_i$ with $\varepsilon_i \sim N(0, \sigma^2)$. The least squares estimators for $\beta_0$ and $\beta_1$ are on the aid sheet---you'll need them here. (In this question for economy of notation I've used lowercase $y$ to refer to "data" and "random variable" interchangeably.)

a. **(1 mark)** Show that the fitted regression line $y = \hat{\beta_0} + \hat{\beta_1}x$ always passes through the point $\left(\overline{x}, \overline{y}\right)$ for any dataset $\{(y_1,x_1),\ldots,(y_n,x_n)\}$.

\vspace{1in}

b. **(2 marks)** Show that $E(\overline{y}) = \beta_0 + \beta_1 \overline{x}$.

\vspace{1.5in}

c. **(2 marks)** Show that $E(\hat{\beta_1}) = \beta_1$.

\pagebreak

**Standard Normal Probabilities $P(Z \le z)$**

```{r, echo=FALSE, results='asis'}
# N(0,1) bottom half
library(stringr)
rows <- -34:0/10
names(rows) <- format(rows, width = 2)
cols <- 0:9/100
names(cols) <- paste0(".", str_pad(0:9, width = 2, pad="0"))
library(xtable)
norm2 <- xtable(pnorm(outer(rows, cols, "-")), digits = 4)
print(norm2, comment=FALSE, scalebox = 1.1)
```

\pagebreak

**Standard Normal Probabilities $P(Z \le z)$**

```{r, echo=FALSE, results='asis'}
# N(0,1) upper half
library(stringr)
rows <- 0:34/10
names(rows) <- format(rows, width = 2)
cols <- 0:9/100
names(cols) <- paste0(".", str_pad(0:9, width = 2, pad="0"))
library(xtable)
norm2 <- xtable(pnorm(outer(rows, cols, "+")), digits = 4)
print(norm2, comment=FALSE, scalebox = 1.1)
```

\pagebreak

```{r, echo=FALSE, results='asis'}
# t table
p <- c(0.3, 0.2, 0.15, 0.1, 0.05, 0.025, 0.02, 0.015, 0.01,
       0.0075, 0.005, 0.0025, 0.0005)
df <- c(11:60, 120, Inf)
t_table <- t(Vectorize(qt, vectorize.args = "df")(p, df, lower.tail = FALSE))
colnames(t_table) <- c(sprintf("%.2f", p[1:5]), format(p)[-c(1:5)])
rownames(t_table) <- c(head(df, -1), "$\\infty$")
t_table_x <- xtable(t_table, digits=3)
addtorow <- list()
addtorow$pos <- list(0,0)
options(scipen=999)
addtorow$command <- c(paste0("& \\multicolumn{", length(p), "}{c}{Upper tail probabilities for $t_\\nu$ distributions $P(t_\\nu \\ge t)$}\\\\\n"), paste0(paste(c("df", p), sep = "", collapse=" & "), "\\\\\n"))
print(t_table_x, comment=FALSE, add.to.row = addtorow, 
      include.colnames = FALSE, scalebox = 0.9,
      sanitize.text.function = function(x) {x})
```

\pagebreak

```{r, echo=FALSE, results='asis'}
# chi^2 table
p <- c(0.3, 0.2, 0.15, 0.1, 0.05, 0.025, 0.02, 0.015, 0.01,
       0.0075, 0.005, 0.0025, 0.0005)
df <- c(1:30)
chi_table <- t(Vectorize(qchisq, vectorize.args = "df")(p, df, lower.tail = FALSE))
colnames(chi_table) <- c(sprintf("%.2f", p[1:5]), format(p)[-c(1:5)])
rownames(chi_table) <- df
chi_table_x <- xtable(chi_table, digits=3)
addtorow <- list()
addtorow$pos <- list(0,0)
options(scipen=999)
addtorow$command <- c(paste0("& \\multicolumn{", length(p), "}{c}{Upper tail probabilities for $\\chi^2_\\nu$ distributions $P(\\chi^2_\\nu \\ge \\chi^2)$}\\\\\n"), paste0(paste(c("df", p), sep = "", collapse=" & "), "\\\\\n"))
print(chi_table_x, comment=FALSE, add.to.row = addtorow, 
      include.colnames = FALSE, scalebox=0.9,
      sanitize.text.function = function(x) {x})
```

\pagebreak

\renewcommand{\d}[2]{\overline #1_{#2\cdot}}
\newcommand{\Var}[1]{\text{Var}\left( #1 \right)}
\newcommand{\Cov}[2]{\text{Cov}\left( #1, #2 \right)}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\E}[1]{\text{E}\left( #1 \right)}
\newcommand{\Sample}[1]{#1_1,\ldots,#1_n}
\newcommand{\od}[2]{\overline #1_{#2\cdot}}
\newcommand{\ol}[1]{\overline #1}

\twocolumn
\raggedright

\begin{center}
  \textbf{Two Samples}
\end{center}

Model: $Y_{ij} = \mu_i + \varepsilon_{ij}$ with $i\in\{1,2\}$ and
$\varepsilon_{ij}$ i.i.d. $N(0, \sigma^2)$.

Pooled sample variance:
$$S^2_p = \frac{(n_1-1)S^2_1 + (n_2-1)S^2_2}{n_1+n_2-2}$$

Test Statistic:
$$T=\frac{(\od{Y}{1} - \od{Y}{2}) - (\mu_1-\mu_2)}
{S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim t_{n_1+n_2-2}$$

$(1-\alpha)\cdot 100\%$ C.I. is

$$\od{Y}{1} - \od{Y}{2} \pm t_{n_1+n_2-2,\alpha/2} S_p
\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$$

Checking assumptions: normal plots and 3:1 SD ratio for equal variance
assumption.

If observations are really ``paired'', use one-sample procedures on
the paired differences using this fact:

$$\frac{\ol{Y_d} - \mu_d}
{S_d/\sqrt{n}} \sim t_{n-1}$$

where $\ol{Y_d}$ is the sample average of the differences, $\mu_d$ is
the mean difference between the two populations, $S_d$ is the sample
standard deviation of the differences and $n$ is the number of paired
observations.

\begin{center}
  \textbf{Simple Linear Regression}
\end{center}
Model: $Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i$ with $\varepsilon_i
\sim N(0, \sigma^2)$

Analysis:
$\hat\beta_0 = \ol y - \hat\beta_1\ol{x}$

$\hat\beta_1 = S_{xy}/S_{xx}$

$S_{xy} = \sum_{i=1}^n (x_i-\ol{x})(y_i - \ol{y})$

$S_{xx} = \sum_{i=1}^n (x_i-\ol{x})^2$

$\Var{\hat\beta_1}=\frac{\sigma^2}{S_{xx}}$

Fitted value at $x_i$ is $\hat{Y}_i = \hat\beta_0+\hat\beta_1x_i$

SS decomposition details:

\begin{tabular}{ccccc} $\sum_{i=1}^n\left(Y_i - \overline Y\right)^2$  &=&
$\sum_{i=1}^n\left(\hat Y_i - \overline Y\right)^2$ &+&
$\sum_{i=1}^n\left(Y_i - \hat Y_i\right)^2$\\
SST &=& SSR &+& SSE\\
$n-1$ d.f. &=& 1 d.f. &+& $n-2$ d.f.
\end{tabular}

Test statistic for $\beta_1$:
$$T=\frac{\hat\beta_1 - \beta_1}{\sqrt{MSE/S_{xx}}}\sim t_{n-2}$$

The denominator is called the ``standard error'' of $\hat\beta_1$

$(1-\alpha)\cdot 100\%$ C.I. for $\beta_1$ is:

$$\hat\beta_1 \pm t_{n-2,\alpha/2} \sqrt{\frac{MSE}{S_{xx}}}$$

Alternate approach for $H_0: \beta_1 = 0$ versus $H_1:
\beta_1 \ne 0$ uses (again\ldots $T^2=F$):
$$F=\frac{SSR/1}{SSE/(n-2)} = \frac{MSR}{MSE} \sim F_{1,n-2}$$

\begin{center}
	\textbf{CI for Proportion}
\end{center}

$$ \hat{p} \pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} $$

Approximately valid if $n\hat p$ and $n(1-\hat p)$ exceed 5.

\begin{center}
  \textbf{Test for Independence}
\end{center}

Given an observed $r$ by $c$ contingency table compute the expected
cell counts $E_i$ by keeping the row and column totals fixed. The test
statistic is then:

$$ \chi^2_{obs} = \sum_{i=1} \frac{\left(O_i - E_i\right)^2}{E_i}$$

where the sum is over all entries in the table, and has an approximate
$\chi^2$ distribution with $(r-1)\times(c-1)$ degrees of freedom as
long as the $E_i$ all exceed 5.
